{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will build on all we have learnt so far about loading and manipulating (spatial) data and apply it to one of the most commonly used forms of spatial analysis: choropleths. Remember these are maps that display the spatial distribution of a variable encoded in a color scheme, also called *palette*. Although there are many ways in which you can convert the values of a variable into a specific color, we will focus in this context only on a handful of them, in particular:\n",
    "\n",
    "* Unique values.\n",
    "* Equal interval.\n",
    "* Quantiles.\n",
    "* Fisher-Jenks.\n",
    "\n",
    "In addition, we will cover how to add base maps that provide context from rasters and, in two optional extensions, will review two more additional ways of displaying data in maps: cartograms and conditional maps.\n",
    "\n",
    "Before all this mapping fun, let us get the importing of libraries and data loading out of the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "import pysal as ps\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For this tutorial, we will use the recently released 2015 Index of Multiple Deprivation (IMD) for England and Wales. This dataset can be most easily downloaded from the CDRC data store ([link](https://data.cdrc.ac.uk/dataset/cdrc-english-indices-of-deprivation-2015-geodata-pack-liverpool-e08000012)) and, since it already comes both in tabular as well as spatial data format (shapefile), it does not need merging or joining to additional geometries.\n",
    "\n",
    "Although all the elements of the IMD, including the ranks and the scores themselves, are in the IMD dataset, we will also be combining them with additional data from the Census, to explore how deprivation is related to other socio-demographic characteristics of the area. For that we will revisit the Census Data Pack ([link](https://data.cdrc.ac.uk/dataset/cdrc-2011-census-data-packs-for-local-authority-district-liverpool-e08000012)) we used previously.\n",
    "\n",
    "In order to create maps with a base layer that provides context, we will be using a raster file derived from [OS VectorMap District (Backdrop Raster)](https://www.ordnancesurvey.co.uk/business-and-government/products/vectormap-district.html) and available for download on [this link](http://darribas.org/gds15/content/labs/figs/lab04_liverpool.tif).\n",
    "\n",
    "As usual, let us set the paths to the folders containing the files before anything so we can then focus on data analysis exclusively (keep in mind the specific paths will probably be different for your computer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be different on your computer and will depend on where\n",
    "# you have downloaded the files\n",
    "imd_shp = './data/shapefiles/E08000012.shp'\n",
    "liv_path = './data/lab04_liverpool.tif'\n",
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **IMD data**\n",
    "\n",
    "Now we can load up the IMD data exactly as we did earlier for a shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file in\n",
    "imd = gpd.read_file(imd_shp)\n",
    "# Index it on the LSOA ID\n",
    "imd = imd.set_index('LSOA11CD')\n",
    "# Display summary\n",
    "imd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how on line 4 we *index* the resulting table `imd` with the column `LSOA11CD`. Effectively, this means we are \"naming\" the rows, the same way we the columns are named, using the column `LSOA11CD`, which contains the unique ID's of each area. This affords us some nice slicing and querying capabilities as well as permitting to merge the table with other ones more easily. \n",
    "\n",
    "Pay attention also to how exactly we index the table: we create a new object that is named in the same way, `imd`, but that contains the result of applying the function `set_index` to the original object `imd`. As usual, there are many ways to index a table in Python, but this is one of the most direct and expressive ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Census data**\n",
    "\n",
    "In order to explore additional dimensions of deprivation, and to have categorical data to display with \"unique values\" choropleths, we will use some of the Census data pack. Although most of the Census variables are continuous, we will transform them to create *categorical* characteristics. Remember a categorical variable is one that comprises only a limited number of potential values, and these are not comparable with each other across a numerical scale. For example, religion or country of origin are categorical variables. It is not possible to compare their different values in a quantitative way (religion A is not double or half of religion B) but instead they represent qualitative differences.\n",
    "\n",
    "In particular, we are going to use tables `QS104EW` (Gender) and `KS103EW` (marital status). The way these are presented in its raw form is as tabulated counts of each of the possible categories. Our strategy to turn these into a single categorical variable for each case is to compare the counts for each area and assign that of the largest case. For example, in the first case, an area will be labelled as \"male\" if there are more males than females living in that particular LSOA. In the case of marital status, although there are more cases, we will simplify and use only \"married\" and \"single\" and assign one or the other on the bases of which ones are more common in each particular area.\n",
    "\n",
    "**NOTE**: the following code snippet involves some data transformations that are a bit more advanced that what is covered in this course. Simply run them to load the data, but you are not expected to know some of the coding tricks required in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Gender breakup\n",
    "# Read table (csv file)\n",
    "gender = pd.read_csv(data_path+'tables/QS104EW_lsoa11.csv', index_col='GeographyCode')\n",
    "# Rename columns from code to human-readable name\n",
    "gender = gender.rename(columns={'QS104EW0002': 'Male', \\\n",
    "                                'QS104EW0003': 'Female'})[['Male', 'Female']]\n",
    "# Create male-female switcher\n",
    "maj_male = gender['Male'] > gender['Female']\n",
    "# Add \"Gender_Majority\" variable to table and assign the switcher\n",
    "gender['Gender_Majority'] = maj_male\n",
    "# Replace `True` values with \"Male\" and `False` with \"Female\"\n",
    "gender.loc[gender['Gender_Majority']==True, 'Gender_Majority'] = 'Male'\n",
    "gender.loc[gender['Gender_Majority']==False, 'Gender_Majority'] = 'Female'\n",
    "\n",
    "                # Status breakup\n",
    "# Read table (csv file)\n",
    "sinmar = pd.read_csv(data_path+'tables/KS103EW_lsoa11.csv', index_col='GeographyCode')\n",
    "# Rename columns from code to human-readable name\n",
    "sinmar = sinmar.rename(columns={'KS103EW0002': 'Single', \\\n",
    "                                'KS103EW0003': 'Married'})[['Single', 'Married']]\n",
    "# Create sigle-married switcher\n",
    "maj_sin = sinmar['Single'] > sinmar['Married']\n",
    "# Add \"Status_Majority\" variable to table and assign the switcher\n",
    "sinmar['Status_Majority'] = maj_sin\n",
    "# Replace `True` values with \"Single\" and `False` with \"Married\"\n",
    "sinmar.loc[sinmar['Status_Majority']==True, 'Status_Majority'] = 'Single'\n",
    "sinmar.loc[sinmar['Status_Majority']==False, 'Status_Majority'] = 'Married'\n",
    "\n",
    "# Join\n",
    "both = imd.join(sinmar).join(gender)\n",
    "# Reset the CRS after join\n",
    "both.crs = imd.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the table we will be using for the rest of the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at the variables reveals that, in effect, we have successfuly merged the IMD data with the categorical variables derived from Census tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are fully ready to map!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A choropleth for categorical variables simply assigns a different color to every potential value in the series. The main requirement in this case is then for the color scheme to reflect the fact that different values are not ordered or follow a particular scale.\n",
    "\n",
    "In Python, thanks to `geopandas`, creating categorical choropleths is possible with one line of code. To demonstrate this, we can plot the spatial distribution of LSOAs with a more female population than male and viceversa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "both.plot(column='Gender_Majority', categorical=True, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us stop for a second in a few crucial aspects:\n",
    "\n",
    "* Note how we are using the same approach as for basic maps, the command `plot`, but we now need to add the argument `column` to specify which column in particular is to be represented.\n",
    "* Since the variable is categorical we need to make that explicit by setting the argument `categorical` to `True`.\n",
    "* As an optional argument, we can set `legend` to `True` and the resulting figure will include a legend with the names of all the values in the map.\n",
    "* Unless we specify a different colormap, the selected one respects the categorical nature of the data by not implying a gradient or scale but a qualitative structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[Optional exercise]**\n",
    "\n",
    "Create a categorical map of the marital status in Liverpool. Where are the areas with more married than single population?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, instead of categorical variables, we want to display the geographical distribution of a continuous phenomenon, we need to select a way to encode each value into a color. One potential solution is applying what is usually called \"equal intervals\". The intuition of this method is to split the *range* of the distribution, the difference between the minimum and maximum value, into equally large segments and to assign a different color to each of them according to a palette that reflects the fact that values are ordered.\n",
    "\n",
    "Using the example of the position of a LSOA in the national ranking of the IMD (`imd_rank`), we can calculate these segments, also called bins or buckets, using the library `PySAL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi = ps.Equal_Interval(imd['imd_rank'], k=7)\n",
    "classi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only additional argument to pass to `Equal_Interval`, other than the actual variable we would like to classify is the number of segments we want to create, `k`, which we are arbitrarily setting to seven in this case. This will be the number of colors that will be plotted on the map so, although having several can give more detail, at some point the marginal value of an additional one is fairly limited, given the ability of the brain to tell any differences.\n",
    "\n",
    "Once we have classified the variable, we can check the actual break points where values stop being in one class and become part of the next one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi.bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array of breaking points above implies that any value in the variable below 4604.9 will get the first color in the gradient when mapped, values between 4604.9 and 9185.7 the next one, and so on.\n",
    "\n",
    "The key characteristic in equal interval maps is that the bins are allocated based on the magnitude on the values, irrespective of how many obervations fall into each bin as a result of it. In highly skewed distributions, this can result in bins with a large number of observations, while others only have a handful of outliers. This can be seen in the submmary table printed out above, where 156 LSOAs are in the first group, but only five of them belong to the one with highest values. This can also be represented visually with a kernel density plot where the break points are included as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "f, ax = plt.subplots(1)\n",
    "# Plot the kernel density estimation (KDE)\n",
    "sns.kdeplot(imd['imd_rank'], shade=True)\n",
    "# Add a blue tick for every value at the bottom of the plot (rugs)\n",
    "sns.rugplot(imd['imd_rank'], alpha=0.5)\n",
    "# Loop over each break point and plot a vertical red line\n",
    "for cut in classi.bins:\n",
    "    plt.axvline(cut, color='red', linewidth=0.75)\n",
    "# Display image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically speaking, the figure is created by overlaying a KDE plot with vertical bars for each of the break points. This makes much more explicit the issue highlighed by which the first bin contains a large amount of observations while the one with top values only encompasses a handful of them.\n",
    "\n",
    "To create a map that displays the colors assigned by the equal interval classification algorithm, we use a similar approach as with unique values but with some key differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd.plot(column='imd_rank', scheme='equal_interval', k=7, colormap=plt.cm.Blues_r, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the key differences:\n",
    "\n",
    "* Instead of specifyig `categorical` as `True`, we replace it by the argument `scheme`, which we will use for all choropleths that require a continuous classification scheme. In this case, we set it to `equal_interval`.\n",
    "* As above, we set the number of colors to 7. Note that we need not pass the bins we calculated above, the plotting method does it itself under the hood for us.\n",
    "* As optional arguments, we can change the colormap to a blue gradient, which is one of the recommended ones by [ColorBrewer](http://colorbrewer2.org/) for a sequential palette.\n",
    "* Equally optional, some of the arguments we learned with basic maps, such as the degree of transparency, also apply in this context.\n",
    "\n",
    "Substantively, the map also makes very explicit the fact that many areas are put into the same bin as the amount of white polygons is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[Optional exercise]**\n",
    "\n",
    "Create an equal interval kde plot and map of the actual score of the IMD (`imd_score`). \n",
    "\n",
    "As a bonus, try including a legend in the map, following a similar approach as in unique values maps.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One solution to obtain a more balanced classification scheme is using quantiles. This, by definition, assigns the same amount of values to each bin: the entire series is laid out in order and break points are assigned in a way that leaves exactly the same amount of observations between each of them. This \"observation-based\" approach contrasts with the \"value-based\" method of equal intervals and, although it can obscure the magnitude of extreme values, it can be more informative in cases with skewed distributions.\n",
    "\n",
    "Calculating a quantiles classification with `PySAL` can be done with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi = ps.Quantiles(imd['imd_rank'], k=7)\n",
    "classi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, similarly, the bins can also be inspected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi.bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization of the distribution can be generated in a similar way as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "f, ax = plt.subplots(1)\n",
    "# Plot the kernel density estimation (KDE)\n",
    "sns.kdeplot(imd['imd_rank'], shade=True)\n",
    "# Add a blue tick for every value at the bottom of the plot (rugs)\n",
    "sns.rugplot(imd['imd_rank'], alpha=0.5)\n",
    "# Loop over each break point and plot a vertical red line\n",
    "for cut in classi.bins:\n",
    "    plt.axvline(cut, color='red', linewidth=0.75)\n",
    "# Display image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the choropleth also follows a similar pattern, with the difference that we are now using the scheme \"quantiles\", instead of \"equal interval\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd.plot(column='imd_rank', scheme='QUANTILES', alpha=1, k=7, \\\n",
    "         colormap=plt.cm.Blues_r, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how, in this case, the amount of polygons in each color is by definition much more balanced (almost equal in fact, except for rounding differences). This obscures outlier values, which get blurred by significantly smaller values in the same group, but allows to get more detail in the \"most populated\" part of the distribution, where instead of only white polygons, we can now discern more variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[Optional exercise]**\n",
    "\n",
    "Create a quantile kde plot and map of the actual score of the IMD (`imd_score`). \n",
    "\n",
    "As a bonus, make a map with 50% of transparency and no boundary lines.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher-Jenks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equal interval and quantiles are only two examples of very many classification schemes to encode values into colors. Although not all of them are integrated into `geopandas`, `PySAL` includes several other classification schemes (for a detailed list, have a look at this [link](http://pysal.readthedocs.org/en/latest/library/esda/mapclassify.html)). As an example of a more sophisticated one, let us create a Fisher-Jenks choropleth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi = ps.Fisher_Jenks(imd['imd_rank'], k=7)\n",
    "classi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This methodology aims at minimizing the variance *within* each bin while maximizing that *between* different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi.bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphically, we can see how the break points are not equally spaced but are adapting to obtain an optimal grouping of observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd.plot(column='imd_rank', scheme='QUANTILES', alpha=1, k=7, colormap=plt.cm.Blues_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "f, ax = plt.subplots(1)\n",
    "# Plot the kernel density estimation (KDE)\n",
    "sns.kdeplot(imd['imd_rank'], shade=True)\n",
    "# Add a blue tick for every value at the bottom of the plot (rugs)\n",
    "sns.rugplot(imd['imd_rank'], alpha=0.5)\n",
    "# Loop over each break point and plot a vertical red line\n",
    "for cut in classi.bins:\n",
    "    plt.axvline(cut, color='red', linewidth=0.75)\n",
    "# Display image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, however, the way to create a Fisher-Jenks map is exactly the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd.plot(column='imd_rank', scheme='fisher_jenks', alpha=1, k=7, colormap=plt.cm.Blues_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster basemaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section requires the additional library `rasterio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since choropleths tend to be based on administrative boundaries which do not necessarily reflect correctly the topography of a region, it may be of interest to provide a choropleth with certain geographical context. If data are available, an easy way to deliver this is by plotting a base raster map underneath the choropleth and allowing some transparency on the upper layer.\n",
    "\n",
    "To do this in Python, we can combine the plotting of a raster image with the generation of a choropleth as we have seen above. First, we need to read the raster in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open the raster file\n",
    "src = rasterio.open(liv_path)\n",
    "# Extract the bounds\n",
    "left, bottom, right, top = src.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are ready to generate the figure with both layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Set up the figure\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "# Add raster layer\n",
    "ax.imshow(src.read(1), cmap='gray', extent=(left, right, bottom, top))\n",
    "# Create the choropleth\n",
    "imd.plot(column='imd_score', colormap='Blues', linewidth=0.1, axes=ax)\n",
    "# Style the labels for the ticks\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=90)\n",
    "# Keep axes proportionate\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the way the raster is added to the axis is different that the way we attach a vector map: the raster gets plotted through `imshow` (image show), which is a function embedded in the axis object (`ax`), while the vector object is appended by passing the axis (`ax`) through the plotting method itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zooming into the map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general map of an entire region, or urban area, can sometimes obscure particularly local patterns because they happen at a much smaller scale that cannot be perceived in the global view. One way to solve this is by providing a focus of a smaller part of the map in a separate figure. Although there are many ways to do this in Python, the most straightforward one is to reset the limits of the axes to center them in the area of interest.\n",
    "\n",
    "As an example, let us consider the quantile map produced above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd.plot(column='imd_rank', scheme='QUANTILES', alpha=1, k=7, colormap=plt.cm.Blues_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to focus on the city centre, say the area of the map more or less between coordinates 387,000 and 391,000 on the vertical axis, and 332,000 and 337,000 on the horizontal one, creating the figure involves the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the figure\n",
    "f, ax = plt.subplots(1)\n",
    "# Draw the choropleth\n",
    "imd.plot(column='imd_rank', scheme='QUANTILES', alpha=1, k=7, \\\n",
    "         colormap=plt.cm.Blues_r, axes=ax)\n",
    "# [Optional] Keep axes proportionate\n",
    "plt.axis('equal')\n",
    "# Redimensionate X and Y axes to desired bounds\n",
    "ax.set_ylim(387000, 391000)\n",
    "ax.set_xlim(332000, 337000)\n",
    "# Show image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how, if we decide to keep the axes proportionate, it needs to be done *before* resetting the limits, as otherwise the change will not have an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[Extension 1]` Cartograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cartograms are maps that represent the spatial distribution of a variable not by encoding it in a color palette by rather by modifying geographical objects. There are many algorithms to distort the shapes of geographical entities according to values, some of them incredibly complicated and complex. \n",
    "\n",
    "As an example of how to create a relatively straight-forward cartogram, we will convert polygons into points by using their centroids, and will define the size of the dot proportionally to the value of the variable we want to display, the IMD score in this case. We will adopt a different approach to plot points than we have done so far. This involves first extracting the coordinates of the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.array([(pt.x, pt.y) for pt in imd.centroid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The line of code above contains some elements that reflect more advanced Python programming that we have covered so far, so you should feel free to simply run it to extract the points.\n",
    "\n",
    "---\n",
    "\n",
    "If you are interested in the logic however, it uses a technique called \"list comprehension\", which can compress and entire `for` loop into a single line of code, producing more elegant and, to the trained eye, more readable code. Essentially, the line above can be unpacked into the following loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = []\n",
    "for pt in imd.centroid:\n",
    "    pts.append((pt.x, pt.y))\n",
    "pts = np.array(pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Once we have extracted them, we can display them through the command `plt.scatter`. This is equivalent to the straightforward `plot`, or to loop over each point, with the difference that it will allow us to modify the size of the dots according to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dots, using `imd_score` as a variable to modify\n",
    "# the size of each dot\n",
    "plt.scatter(pts[:, 0], pts[:, 1], s=imd['imd_score'].values)\n",
    "# Keep axes proportionate\n",
    "plt.axis(\"equal\")\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `plt.scatter` can also take some of the optional arguments we have learned before, such as color. Have a look at the help of the command ([link](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter)) and try modifying some of them to explore changes in the resulting plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[Extension 2 - Advanced]` Conditional maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional maps are an attempt to explore multivariate relationships within a choropleth mapping context. In essence, they are figures composed by several choropleths in which the layout of each of them provides information about the subset of the original dataset represented. The idea is that a dataset can be subset based on one or two conditional variables, usually categorical, and only the observations that meet each characteristic are displayed in a given submap. Since they are combinations of choropleths, they build on everything we have learned about their creation. As an example, let us create a conditional map of IMD scores based on the dominating gender and marital status of each area.\n",
    "\n",
    "From a Python perspective, creating conditional maps is a bit more intricate than simple choropleths because of the conditioning of the data and the arranging of the layout that needs to occur for the final figure to be produced. To be able to use the facetting machinery available in `seaborn`, we need to define a function that generates a choropleth with a given subset of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_subset(vals, db, color=None, norm=True):\n",
    "    '''\n",
    "    Internal function to pass to `FaceGrid` to build a single map\n",
    "    ...\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    vals     : Series\n",
    "               Values of the subplot to be mapped\n",
    "    db       : GeoDataFrame\n",
    "               Table with geometries\n",
    "    color    : None\n",
    "    '''\n",
    "    ax = plt.gca()\n",
    "    for poly in db['geometry']:\n",
    "        gpd.plot(ax, poly, facecolor='grey', linewidth=0.)\n",
    "    vari = vals.name\n",
    "    if norm:\n",
    "        db.reindex(vals.index).plot(column=vari, axes=ax, colormap='Blues', linewidth=0., \\\n",
    "                               vmin=db[vari].min(), vmax=db[vari].max())\n",
    "    else:\n",
    "        db.reindex(vals.index).plot(column=vari, axes=ax, colormap='Blues', linewidth=0.)\n",
    "    ax.set_axis_off()\n",
    "    plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function in hand, we can use it to pass it on to the facetting functionality in `seaborn`, which then takes care of the actual subsetting of the data and proper alignment of the output figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# g = sns.FacetGrid(both, row=\"Gender_Majority\", col=\"Status_Majority\", \\\n",
    "#                   margin_titles=True, size=5)\n",
    "# g.map(map_subset, \"imd_score\", db=both)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure contains a few interesting elements:\n",
    "\n",
    "* The distribution of areas with different characteristics is not random over space but rather follows a specific pattern. For example, the majority of married/female areas are located in the periphery of the city, while most of the single/male LSOAs can be found in the city centre. \n",
    "* Since the color scale is common across maps, we can compare the degree of deprivation for different combinations. For example, areas with a more married population display consistently lower levels of deprivation than those where singles prevail.\n",
    "\n",
    "Although conditional maps are a powerful tool to explore a dataset and generate hypotheses about multivariate relationships, it is important to keep in mind these can only be suggestive. A more formal analysis, such as one based on regression, would be required to establish more robust conclusions, as several confounding factors can be at play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[Extension 3 - Advanced]` MAUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although arguably a bit more advanced, if you are curious how the maps that exemplify the [Modifiable Areal Unit Problem](https://en.wikipedia.org/wiki/Modifiable_areal_unit_problem) (MAUP) in the lecture slides, you can find a notebook illustrating it on this link:\n",
    "\n",
    "> [https://gist.github.com/darribas/8b5a7b93d4085223f1c5#file-maup-ipynb](https://gist.github.com/darribas/8b5a7b93d4085223f1c5#file-maup-ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[Extension 4]` Maps from lecture slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "both.plot(column='Status_Majority', categorical=True, legend=True, axes=ax, \\\n",
    "          linewidth=0.1, colormap='Set3')\n",
    "ax.set_title('Status Majority')\n",
    "plt.axis('equal')\n",
    "#plt.savefig('../lectures/figs/l04_unique_values.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Choropleth classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scheme(scheme, var, db, figsize=(16, 8), saveto=None):\n",
    "    '''\n",
    "    Plot the distribution over value and geographical space of variable `var` using scheme `scheme\n",
    "    ...\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    scheme   : str\n",
    "               Name of the classification scheme to use \n",
    "    var      : str\n",
    "               Variable name \n",
    "    db       : GeoDataFrame\n",
    "               Table with input data\n",
    "    figsize  : Tuple\n",
    "               [Optional. Default = (16, 8)] Size of the figure to be created.\n",
    "    saveto   : None/str\n",
    "               [Optional. Default = None] Path for file to save the plot.\n",
    "    '''\n",
    "    from pysal.esda.mapclassify import Quantiles, Equal_Interval, Fisher_Jenks\n",
    "    schemes = {'equal_interval': Equal_Interval, \\\n",
    "               'quantiles': Quantiles, \\\n",
    "               'fisher_jenks': Fisher_Jenks}\n",
    "    classi = schemes[scheme](db[var], k=7)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    # KDE\n",
    "    sns.kdeplot(db[var], shade=True, ax=ax1)\n",
    "    sns.rugplot(db[var], alpha=0.5, ax=ax1)\n",
    "    for cut in classi.bins:\n",
    "        ax1.axvline(cut, color='red', linewidth=0.75)\n",
    "    ax1.set_title('Value distribution')\n",
    "    # Map\n",
    "    p = db.plot(column=var, scheme=scheme, alpha=0.75, k=7, \\\n",
    "             colormap=plt.cm.Blues_r, axes=ax2, linewidth=0.1)\n",
    "    ax2.axis('equal')\n",
    "    ax2.set_axis_off()\n",
    "    ax2.set_title('Geographical distribution')\n",
    "    f.suptitle(scheme, size=25)\n",
    "    if saveto:\n",
    "        plt.savefig(saveto)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_scheme('equal_interval', 'imd_rank', imd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conditional map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_scheme('quantiles', 'imd_rank', imd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
